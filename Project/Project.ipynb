{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bL2aFZE7ZKbyPRt3GUx35bz5_YK0OcXh",
      "authorship_tag": "ABX9TyNlt0UEx9aU5zEng+gEQjJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilbertcaine/COMP4211/blob/main/Project/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj4luAPGr0c0",
        "outputId": "1d494edd-93af-43c5-ae50-ee3fa9c933ac"
      },
      "source": [
        "# https://drive.google.com/file/d/199mVXHt5cxT68gBXCcucMjtJzCwvc8ud/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1d2hJyvo2Go4FxK7br0exFQFdZ1eCexIA/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1yjsMICWqHdEUhF758ndq0hLO96FrYWkR/view?usp=sharing\n",
        "%cd /content\n",
        "!mkdir -p dataset\n",
        "%cd /content/dataset\n",
        "!gdown --id 199mVXHt5cxT68gBXCcucMjtJzCwvc8ud\n",
        "!gdown --id 1d2hJyvo2Go4FxK7br0exFQFdZ1eCexIA\n",
        "!gdown --id 1yjsMICWqHdEUhF758ndq0hLO96FrYWkR\n",
        "%cd ../"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/dataset\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=199mVXHt5cxT68gBXCcucMjtJzCwvc8ud\n",
            "To: /content/dataset/train.csv\n",
            "100% 7.62M/7.62M [00:00<00:00, 116MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d2hJyvo2Go4FxK7br0exFQFdZ1eCexIA\n",
            "To: /content/dataset/Test_Jan.csv\n",
            "100% 124k/124k [00:00<00:00, 45.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yjsMICWqHdEUhF758ndq0hLO96FrYWkR\n",
            "To: /content/dataset/Predict_Jan.csv\n",
            "100% 20.7k/20.7k [00:00<00:00, 39.1MB/s]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WdaeGZWPlaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49ac672-815f-4b59-b15c-12db7da14b4d"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "!pip install torchsummaryX\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path as osp\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.1.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (3.10.0.2)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erhn50AnU9z3"
      },
      "source": [
        "def train_epoch(net, optimizer, loss_fn, dataloader, epoch, train_size, writer=None, device='cpu'):\n",
        "    ep_loss = 0.0\n",
        "    num_iter = len(dataloader)\n",
        "    net.train()\n",
        "    grad_max = 100.\n",
        "    for n_iter, (xs, y) in enumerate(dataloader):\n",
        "        curr_iter = epoch * num_iter + n_iter\n",
        "        xs, y = xs.to(device), y.to(device)\n",
        "        pred = net(xs) ## step 1. get output\n",
        "        loss = loss_fn(pred, y) ## step 2. compute loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() ## step 3. backpropagation\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), grad_max) ## L2-norm gradient clipping\n",
        "        optimizer.step() ## step 4. update model weigth\n",
        "        if writer is not None:\n",
        "            writer.add_scalar('Loss/train', loss.data, curr_iter)\n",
        "        # print(\"\\n[ITER %d] LOSS: %.4f\" % (curr_iter, loss.data))\n",
        "        ep_loss += loss.data\n",
        "        if n_iter + 1 == train_size:\n",
        "            break\n",
        "    ep_loss /= train_size\n",
        "    if writer is not None:\n",
        "        writer.add_scalar('EpLoss/train', ep_loss, epoch)\n",
        "    return ep_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def val_epoch(net, loss_fn, dataloader, epoch, val_set, writer=None, device='cpu'):\n",
        "    ep_loss = 0.0\n",
        "    net.eval()\n",
        "    preds, ys = [], []\n",
        "    for n_iter, (xs, y) in enumerate(dataloader):\n",
        "        xs, y = xs.to(device), y.to(device)\n",
        "        pred = net(xs)\n",
        "        loss = loss_fn(pred, y)\n",
        "        ep_loss += loss.data\n",
        "    ep_loss /= len(dataloader)\n",
        "\n",
        "    if writer is not None:\n",
        "        writer.add_scalar('EpLoss/val', ep_loss, epoch)\n",
        "    return ep_loss\n",
        "\n",
        "def train(net, train_set, val_set, loss_fn, batch_size, lr, n_epoch, train_size, name='net'):\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1)\n",
        "\n",
        "    save_dir = f'drive/MyDrive/COMP4211/project/logs/{name}_{batch_size}_{lr}'\n",
        "    writer = SummaryWriter(log_dir=osp.join(save_dir, 'log'))\n",
        "    device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
        "    net = net.to(device)\n",
        "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
        "\n",
        "    train_ep_losses, val_ep_losses = [], []\n",
        "    min_loss = 0\n",
        "    argmin_loss = 0\n",
        "    for epoch in range(n_epoch):\n",
        "        train_loss = train_epoch(net, optimizer, loss_fn, train_loader, epoch, train_size, writer, device)\n",
        "        val_loss = val_epoch(net, loss_fn, val_loader, epoch, val_set, writer, device)\n",
        "        train_ep_losses.append(train_loss)\n",
        "        val_ep_losses.append(val_loss)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(\"[EP \\t%d] \\t\\tTrain LOSS: \\t%.4f \\t\\tVal LOSS: \\t%.4f\" % (epoch + 1, train_loss, val_loss))\n",
        "            os.makedirs(osp.join(save_dir, 'weights'), exist_ok=True)\n",
        "            torch.save(net.state_dict(), osp.join(save_dir, 'weights/ep%d.pth' % (epoch + 1)))\n",
        "            if argmin_loss == 0:\n",
        "                min_loss = val_loss\n",
        "            if min_loss >= val_loss:\n",
        "                min_loss = val_loss\n",
        "                argmin_loss = epoch + 1\n",
        "    \n",
        "    plt.plot(torch.tensor(train_ep_losses).cpu().numpy(), label='train')\n",
        "    plt.plot(torch.tensor(val_ep_losses).cpu().numpy(), label='val')\n",
        "    plt.xlabel('n_epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return argmin_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(net, loss_fn, test_data, batch_size, lr, epoch=90, name='net'):\n",
        "    net.eval()\n",
        "    device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
        "    net = net.to(device)\n",
        "    save_dir = f'drive/MyDrive/COMP4211/project/logs/{name}_{batch_size}_{lr}'\n",
        "    net.load_state_dict(torch.load(osp.join(save_dir, 'weights/ep%d.pth' % epoch)))\n",
        "    test_loader = DataLoader(test_set, batch_size=1)\n",
        "    ep_loss = 0.0\n",
        "    preds, ys = [], []\n",
        "    for n_iter, (xs, y) in enumerate(test_loader):\n",
        "        xs, y = xs.to(device), y.to(device)\n",
        "        pred = net(xs)\n",
        "        loss = loss_fn(pred, y)\n",
        "        ep_loss += loss.data\n",
        "    ep_loss /= len(test_loader)\n",
        "    return ep_loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qacsycRNbddB"
      },
      "source": [
        "# FC_Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1yJgcOiuASt"
      },
      "source": [
        "class FC_Net_Dataset(Dataset):\n",
        "    def __init__(self, split, eval_len=1, csv_dir='dataset/train.csv'):\n",
        "        \"\"\"\n",
        "        Keyword arguments:\n",
        "        split -- an integer either 0, 1, or 2 which indicates train, validation, or test respectively\n",
        "        eval_len -- an integer indicating the number of future timestamp to be predicted\n",
        "        \"\"\"\n",
        "        super(FC_Net_Dataset, self).__init__()\n",
        "        df = pd.read_csv(csv_dir)\n",
        "        df['datetime']=pd.to_datetime(df['datetime'])\n",
        "        df['week_day']=df['datetime'].dt.dayofweek\n",
        "        # df['date']=df['datetime'].dt.day\n",
        "        # df['month']=df['datetime'].dt.month\n",
        "        df['hour']=df['datetime'].dt.hour\n",
        "        df = df.drop(columns=\"datetime\")\n",
        "        data = np.split(df, [int(.7*len(df)), int(.85*len(df))])\n",
        "        self.data = np.array(data[split])\n",
        "        self.eval_len = eval_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = np.random.randint(1, len(self.data)-1 - self.eval_len)\n",
        "        prev_nat_demand = np.reshape(self.data[idx-1][0], -1)\n",
        "        curr_feat = np.concatenate((prev_nat_demand, self.data[idx][1:]))\n",
        "        curr_nat_demand = np.reshape(self.data[idx][0], -1)\n",
        "        return curr_feat, curr_nat_demand\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVtd5j6awL6"
      },
      "source": [
        "class FC_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FC_Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(18, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.bn1 = nn.BatchNorm1d(32, affine=True)\n",
        "        self.fc3 = nn.Linear(32, 8)\n",
        "        self.bn2 = nn.BatchNorm1d(8, affine=True)\n",
        "        self.fc4 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "wZXCY3g9PoCn",
        "outputId": "13f95206-8e6c-408a-c3c5-b8691ff54e59"
      },
      "source": [
        "train_set = FC_Net_Dataset(split=0)\n",
        "val_set = FC_Net_Dataset(split=1)\n",
        "\n",
        "np.random.seed(1)\n",
        "fc_net = FC_Net();\n",
        "loss_fn = nn.L1Loss()\n",
        "batch_size, n_epoch, lr = 32, 100, 1e-3\n",
        "train_size, val_size = 365, 365\n",
        "argmin_loss = train(fc_net, train_set, val_set, loss_fn, batch_size, lr, n_epoch, train_size, name='fc_net')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP \t5] \t\tTrain LOSS: \t1097.5331 \t\tVal LOSS: \t1140.0734\n",
            "[EP \t10] \t\tTrain LOSS: \t935.8558 \t\tVal LOSS: \t932.4814\n",
            "[EP \t15] \t\tTrain LOSS: \t706.9833 \t\tVal LOSS: \t807.0226\n",
            "[EP \t20] \t\tTrain LOSS: \t466.4998 \t\tVal LOSS: \t526.4249\n",
            "[EP \t25] \t\tTrain LOSS: \t315.2100 \t\tVal LOSS: \t392.2273\n",
            "[EP \t30] \t\tTrain LOSS: \t212.7604 \t\tVal LOSS: \t217.4704\n",
            "[EP \t35] \t\tTrain LOSS: \t125.7602 \t\tVal LOSS: \t116.2987\n",
            "[EP \t40] \t\tTrain LOSS: \t56.9699 \t\tVal LOSS: \t143.5609\n",
            "[EP \t45] \t\tTrain LOSS: \t46.0259 \t\tVal LOSS: \t62.0779\n",
            "[EP \t50] \t\tTrain LOSS: \t39.3051 \t\tVal LOSS: \t80.4563\n",
            "[EP \t55] \t\tTrain LOSS: \t35.8394 \t\tVal LOSS: \t40.7716\n",
            "[EP \t60] \t\tTrain LOSS: \t35.7463 \t\tVal LOSS: \t57.0471\n",
            "[EP \t65] \t\tTrain LOSS: \t34.1121 \t\tVal LOSS: \t49.0247\n",
            "[EP \t70] \t\tTrain LOSS: \t32.6266 \t\tVal LOSS: \t54.8916\n",
            "[EP \t75] \t\tTrain LOSS: \t33.2204 \t\tVal LOSS: \t49.4338\n",
            "[EP \t80] \t\tTrain LOSS: \t32.0463 \t\tVal LOSS: \t23.5291\n",
            "[EP \t85] \t\tTrain LOSS: \t32.7897 \t\tVal LOSS: \t29.2587\n",
            "[EP \t90] \t\tTrain LOSS: \t31.9406 \t\tVal LOSS: \t32.9994\n",
            "[EP \t95] \t\tTrain LOSS: \t31.5224 \t\tVal LOSS: \t45.6155\n",
            "[EP \t100] \t\tTrain LOSS: \t32.1488 \t\tVal LOSS: \t35.4233\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c8zk14glQBJIKH3lgBBREDAggVUEBXbyqpr2V11i7juqruu35/rumtZURdFxQ5iQxbFgl2KCdJrqEkIIQRSSJ1kzu+Pe4EIhJYyyczzfr3ymjvnnjvzXK4+9865554jxhiUUkr5BoenA1BKKdV0NOkrpZQP0aSvlFI+RJO+Ukr5EE36SinlQ/w8HcCJxMTEmKSkJE+HoZRSLUpGRsY+Y0zs8dY166SflJREenq6p8NQSqkWRUR21rVOm3eUUsqHaNJXSikfoklfKaV8SLNu01dKqTPhcrnIzs6moqLC06E0qqCgIBISEvD39z/lbTTpK6W8TnZ2NuHh4SQlJSEing6nURhjKCgoIDs7m+Tk5FPeTpt3lFJep6KigujoaK9N+AAiQnR09Gn/mtGkr5TySt6c8A85k308adIXkZdEZK+IrK1V9k8R2Sgiq0XkfRGJqLXuPhHJFJFNInJ+rfIL7LJMEZl+2pGeDmPgh//Awb2N+jVKKdXSnMqV/ivABUeVfQb0Mcb0AzYD9wGISC/gKqC3vc2zIuIUEScwA7gQ6AVcbddtHAWZ8MXDMGMorH2v0b5GKaWOp7CwkGefffa0txs/fjyFhYWNENERJ036xphvgP1HlX1qjKm23y4FEuzlCcDbxphKY8x2IBMYYv9lGmO2GWOqgLftuo0jpivc+g1EJsG8X8A7N0Lpvkb7OqWUqq2upF9dXX2c2kcsXLiQiIiIE9apr4Zo078J+Nhejgeyaq3LtsvqKj+GiNwiIukikp6fn3/mUbXpAdM+g3P/AhsWwDOp8NPrVtOPUko1ounTp7N161YGDBjA4MGDGTFiBJdeeim9elkNHBMnTiQlJYXevXszc+bMw9slJSWxb98+duzYQc+ePbn55pvp3bs35513HuXl5Q0SW726bIrI/UA18EaDRAMYY2YCMwFSU1Prl6GdfnDO76HHRfDRXfDhHbDyLZg4w/oVoJTyen/9aB3rdxc36Gf2at+KBy/pXef6Rx99lLVr17Jy5Uq++uorLrroItauXXu4a+VLL71EVFQU5eXlDB48mCuuuILo6OiffcaWLVt46623eOGFF7jyyit59913ufbaa+sd+xlf6YvIjcDFwFRzZKLdHCCxVrUEu6yu8qbRpif84mO45GnYswbemAyVB5vs65VSvm3IkCE/60v/9NNP079/f9LS0sjKymLLli3HbJOcnMyAAQMASElJYceOHQ0Syxld6YvIBcAfgZHGmLJaq+YDb4rIv4H2QFdgOSBAVxFJxkr2VwHX1Cfw0+ZwQMoNEJUMr06ABXfB5S+AD3TrUsqXneiKvKmEhoYeXv7qq6/4/PPPWbJkCSEhIYwaNeq4fe0DAwMPLzudzgZr3jmVLptvAUuA7iKSLSLTgGeAcOAzEVkpIs8DGGPWAXOB9cAnwB3GmBr7pu+dwCJgAzDXrtv0ks+BUX+CNe9AxsseCUEp5d3Cw8MpKSk57rqioiIiIyMJCQlh48aNLF26tEljO+mVvjHm6uMUzzpB/UeAR45TvhBYeFrR1UNuUTlx4UE4HMe5kh/xO9i1BD6+F9oPgvYDmiospZQPiI6OZvjw4fTp04fg4GDi4uIOr7vgggt4/vnn6dmzJ927dyctLa1JYxPTjHuzpKammjOZRKWwrIoBf/uMIH8HSdGhdIoNZerQjgzvEnOkUmkB/HeE1Ztn2qcQkVj3ByqlWpQNGzbQs2dPT4fRJI63ryKSYYxJPV59rxyGwekQHrmsD9cO7Uh8RDDpOw4w9cVl/PWjdVS4aqxKodFwzVyoKoXXr4Cy/Sf+UKWU8gJeOcpmeJA/U4d2PPy+vKqGRz/ewMvf7+C7Lft45ppBdG8bDm37wNVvwmuXwZtT4PoPISDEg5ErpVTj8sor/aMFBzj564Q+vPKLwRSWu7j82e9ZvDHPWpl0ttWLJ/tHWHSfZwNVSqlG5hNJ/5BR3dvw0Z1nkxwbyi9np/PSd9sxxkDvidB3Emz8nz6xq5Tyaj6V9AHatg5i7q3DGNcrjr8tWM9TX9gPRSSNgNJ82LfZswEqpVQj8rmkDxAS4MdzU1OYOKA9zyzOZNOeEquZB2DHd54NTimlGpFPJn0Ah0N48JLehAf58ecP1uCOSIbwdpr0lVJNLiwsrMm+y2eTPkBkaAD3XdiTH3ccYN5POdBxOOz8Xtv1lVJey6eTPsCklARSO0by/xZuoLT9MDiYBwVbPR2WUqoFmz59OjNmzDj8/qGHHuLvf/87Y8aMYdCgQfTt25cPP/zQI7F5ZT/90+FwCH+/rA8XPf0dT2e2saYA2/kdxHSxKpTsgfJCa3x+pVTL8/F0a3TdhtS2L1z4aJ2rp0yZwl133cUdd9wBwNy5c1m0aBG/+c1vaNWqFfv27SMtLY1LL720yefy9fkrfYAebVtxx+gu/He9g/KA6CPt+jUueO1yeOUiqDnxjDdKKXXIwIED2bt3L7t372bVqlVERkbStm1b/vSnP9GvXz/Gjh1LTk4OeXl5TR6bz1/pH/LbMV1ZmVXI4h3dGLf1WwKMge+fgr32YKA7voXOoz0bpFLq9J3girwxTZ48mXnz5rFnzx6mTJnCG2+8QX5+PhkZGfj7+5OUlHTcIZUbm17p25wO4emrBrAhsB8BZXsoWvMxfP0YdB8PAWGw7n1Ph6iUakGmTJnC22+/zbx585g8eTJFRUW0adMGf39/vvzyS3bu3OmRuDTp1xIREsCECVcCEPD+TRj/ILj4Seh2PmxcoE08SqlT1rt3b0pKSoiPj6ddu3ZMnTqV9PR0+vbty6uvvkqPHp65T6jNO0fp2juFivlRBFft57vkP3B2eBz0mghr39UmHqXUaVmz5sgN5JiYGJYsWXLcegcPNt30rXqlfzQRAlOuYUXIcKat6Unm3hLoOg78Q2H9B56OTiml6kWT/nHI+Y+QcNt7hAT4cc/cVbgcgVYTz4aPtIlHKdWiadKvQ5vwIP7vsr6szi7imcWZ0PsyKCuw+vArpZq95jwrYEM5k33UpH8CF/Ztx6X92/Pc11vZ23aE1cSzZh643Z4OTSl1AkFBQRQUFHh14jfGUFBQQFBQ0GltpzdyT+J353VjwerdvLh0D3/qfgH89BqsfBNCoqH9QLhmDjTxE3VKqRNLSEggOzub/Px8T4fSqIKCgkhISDitbTTpn0TH6FAmDIjn9aU7ue32B4lMGAyl+yAnHbYsgsJdENnx5B+klGoy/v7+JCcnezqMZkmbd07B7aM6U1ZVw0urKyDtNhjzFxh9v7Vy73rPBqeUUqdBk/4p6BoXzoV92vLK9zsoKndZhW16Wq956zwXmFJKnaaTJn0ReUlE9orI2lplUSLymYhssV8j7XIRkadFJFNEVovIoFrb3GDX3yIiNzTO7jSeO0Z3oaSymteW7LAKAsMhooNe6SulWpRTudJ/BbjgqLLpwBfGmK7AF/Z7gAuBrvbfLcBzYJ0kgAeBocAQ4MFDJ4qWok98a87t0YYXv9tOScWhq/3ekKdJXynVcpw06RtjvgH2H1U8AZhtL88GJtYqf9VYlgIRItIOOB/4zBiz3xhzAPiMY08kzd5dY7tSWObihW+3WwVxvaBgC1RXeTYwpZQ6RWfaph9njMm1l/cAcfZyPJBVq162XVZX+TFE5BYRSReR9ObW3apfQgTj+7Zl1rfbKDhYCW16gbsa9m32dGhKKXVK6n0j11hPPzTYExDGmJnGmFRjTGpsbGxDfWyDuWdcd8pdNcz4civE9bYKtV1fKdVCnGnSz7ObbbBf99rlOUBirXoJdlld5S1OlzZhTEpJ4PWlO8lxxoPDX3vwKKVajDNN+vOBQz1wbgA+rFV+vd2LJw0ospuBFgHniUikfQP3PLusRfrt2G4APPXldojpplf6SqkW41S6bL4FLAG6i0i2iEwDHgXGicgWYKz9HmAhsA3IBF4AbgcwxuwHHgZ+tP/+Zpe1SPERwVyb1pF5GdmURnTTHjxKqRbjpMMwGGOurmPVmOPUNcAddXzOS8BLpxVdM/arkZ14fdlOvi1uwwXF2VBeCMERng5LKaVOSJ/IPUNtWgVxZWoC72a3sgr2bvBsQEopdQo06dfDred0ZoO7g/Vmr97MVUo1f5r06yExKoQh/ftSbEIoz7bnwnTXQFGL7JiklPIBmvTr6fbRXdlkEijY9hPkroJZ4+DJPtrco5RqljTp11OXNmGUR3YnrngtZuYoa3x944ZNCz0dmlJKHUOTfgNIGjgOJ27Wt78C7kyHdv1hy2eeDksppY6hM2c1gA4jr+cXG9qzcZ+DbwJa4d/1PPj2X1B+AIJb1GCiSikvp1f6DUGEqSP7kVtUwcI1udD1PKuJZ+tiT0emlFI/o0m/gZzbow2dYkN54dttmPaDrCt8beJRSjUzmvQbiMMhTDs7mbU5xSzdUQRdxlpJ3+32dGhKKXWYJv0GdMWgBKJCA3jx221WE0/ZPsj9ydNhKaXUYZr0G1CQv5Nr0zryxca97IxMA0SbeJRSzYom/QY2dWgHnA7hrbVlkJAKWz71dEhKKXWYJv0GFtcqiNHd2zAvI5uazuMgZwUcbF7TPiqlfJcm/UZw1eBE9h2sZFnAUMDA+g88HZJSSgGa9BvFqO6xtAkPZNbmEIjrA6ve8nRISikFaNJvFH5OB5NSEvhycz7F3SdDTgbkb/J0WEoppUm/sVyZmojbwDtVaSBOWPmmp0NSSilN+o0lKSaUYZ2imb26HNN1HKyeY421r5RSHqRJvxFdNSSRXfvL2NT2EijJhW1fejokpZSP06TfiM7v3ZaIEH+ey+lijcWjTTxKKQ/TpN+IgvydTBqUwP827Kes+2Ww8X9QXujpsJRSPkyTfiO7emgHqt2GjxznQnUFLH3O0yEppXyYJv1G1jk2jGGdovnPhlBM7yvguydg/zZPh6WU8lH1SvoicreIrBORtSLylogEiUiyiCwTkUwRmSMiAXbdQPt9pr0+qSF2oCWYmtaB7APlLOlyFzj94eN7wRhPh6WU8kFnnPRFJB74DZBqjOkDOIGrgH8ATxhjugAHgGn2JtOAA3b5E3Y9n3Ber7bEhAXwypoqGDXdGoTt0MTplSWwYYG29SulmkR9m3f8gGAR8QNCgFzgXGCevX42MNFenmC/x14/RkSknt/fIgT4OZiUksgXG/eyp8eNENvTutp/71Z4vBvMmQrLnvd0mEopH3DGSd8YkwM8DuzCSvZFQAZQaIyptqtlA/H2cjyQZW9bbdePPtPvb2muHpJIjdvw7qo8uOhxKMqCTR9DvykQ0QF262QrSqnGV5/mnUisq/dkoD0QClxQ34BE5BYRSReR9Px87xmSuGN0KEOTo5iXkY3pOBzuzIDfb4JLnoQOZ0HuKk+HqJTyAfVp3hkLbDfG5BtjXMB7wHAgwm7uAUgAcuzlHCARwF7fGig4+kONMTONManGmNTY2Nh6hNf8TEpJYPu+UlbsOgAxXcA/2FrRrr/1xG5JnmcDVEp5vfok/V1AmoiE2G3zY4D1wJfAJLvODcCH9vJ8+z32+sXG+FYXlvF92xES4GReRvbPV7Trb73q1b5SqpHVp01/GdYN2RXAGvuzZgL3AveISCZWm/0se5NZQLRdfg8wvR5xt0ihgX5c2KcdC1blUl5Va/C1tn2tV036SqlG5nfyKnUzxjwIPHhU8TZgyHHqVgCT6/N93mBSSgLvrsjm0/V7mDDAvscd1Aqiu0DuSs8Gp5TyevpEbhMbmhxFQmTw8Zt4cld7JiillM/QpN/EHA7hikEJfJe5j5zC8iMr2vWHol1Qtt9zwSmlvJ4mfQ+YlJKAMTAvvdbV/uGbudrEo5RqPJr0PSAxKoQRXWOY8+Muatx2B6a2/axXvZmrlGpEmvQ95JohHdhdVMFXm/ZaBSFRENFRk75SqlFp0veQsb3iiA0P5K3lu44UtuuvSV8p1ag06XuIv9PBlakJLN64l92Hbui262+NtV9R5NnglFJeS5O+B101uAMGmPNjllXQboD1ql03lVKNRJO+ByVGhXBO11jm/JhFdY0b2tk3c3ct9WxgSimvpUnfw64Z2oE9xRV8uSkfwtpA0gj45p+wa5mnQ1NKeSFN+h42pkcb4loF8vrSnVbB5NnQOh7evlrn0lVKNThN+h7m53Rw1eAOfLMln10FZRAaDVPngXHDG1fqE7pKqQalSb8ZuHpIBxwivLHcvtqP7gxXvQWFO+HLRzwbnFLKq2jSbwbatg5iXM843knPprLaHnK54zCrfV9v6iqlGpAm/Wbi2rSO7C+t4uM1e44Uxg+CvRugqtRzgSmlvIom/WbirM7RJMeEHrmhCxCfAqZG++0rpRqMJv1mwuEQpg7tQPrOA2zILbYK2w+yXnev8FxgSimvokm/GZmUkkCgn4M3l9nj8YTHQasEyMnwbGBKKa+hSb8ZiQgJ4MI+bflwZQ4VLvuGbvxAyNErfaVUw9Ck38xMTk2kuKKaT9fnWQXxKXBgu/bXV0o1CE36zcywTtHERwTzTro9CJu26yulGpAm/WbG4RAmp1pz6GYfKIP2AwDRJh6lVIPQpN8MTUpJAODdjBwIag0xXTXpK6UahCb9ZighMoThnWN4JyMLt9tY7fo5GWCMp0NTSrVwmvSbqcmpCWQfKGfptgKrXb90LxTneDospVQLV6+kLyIRIjJPRDaKyAYRGSYiUSLymYhssV8j7boiIk+LSKaIrBaRQQ2zC97p/N5taRXkx5z0LGs4BtD++kqpeqvvlf5TwCfGmB5Af2ADMB34whjTFfjCfg9wIdDV/rsFeK6e3+3VgvydXDqgPYvW7aE4ojs4/LVdXylVb2ec9EWkNXAOMAvAGFNljCkEJgCz7WqzgYn28gTgVWNZCkSISLszjtwHTEpJpMLlZuH6AxDXC3JXeTokpVQLV58r/WQgH3hZRH4SkRdFJBSIM8bk2nX2AHH2cjyQVWv7bLvsZ0TkFhFJF5H0/Pz8eoTX8vVPaE2XNmHMy8iG2J6wb7OnQ1JKtXD1Sfp+wCDgOWPMQKCUI005ABhjDHBaXU6MMTONManGmNTY2Nh6hNfyiQiTUhJI33mA/SHJ1o3cimJPh6WUasHqk/SzgWxjzKEZvOdhnQTyDjXb2K977fU5QGKt7RPsMnUClw2MxyHw9YFIq0Cv9pVS9XDGSd8YswfIEpHudtEYYD0wH7jBLrsB+NBeng9cb/fiSQOKajUDqTrEtQpiZLdY3twWYhXkb/JsQEqpFs2vntv/GnhDRAKAbcAvsE4kc0VkGrATuNKuuxAYD2QCZXZddQompSTym017cIcE4Mjf6OlwlFItWL2SvjFmJZB6nFVjjlPXAHfU5/t81ZiebQgLDiLXL4F4vdJXStWDPpHbAgT5O7m0f3tWVsTh3qtX+kqpM6dJv4WYnJrAppp4pGgXVJV5OhylVAulSb+F6BvfmtLWXRAMFGzxdDhKqRZKk34LISL07GvdPtmTudLD0SilWipN+i3IqLPSqDYOtq7XgdeUUmdGk34LEtM6nPyABCr3bMRV47YKd3wPa+Z5NjClVIuhSb+FcbTpQceaXXy1KR+qSuGdG+DdX0J2uqdDU0q1AJr0W5iY5H50dOTx/o9bYfkLUJpvTak4/zdQ4/J0eEqpZk6TfgvjbNMDP9zkb1mO+/unoMtYmPgs7F0H3z/l6fCUUs2cJv2WJtYa6ugBx8s4yvfD6D9Bj4ug56Xw9WOwL9PDASqlmjNN+i1NTFdA6OvYwbKAodak6QDj/wl+QbDw9x4NTynVvGnSb2n8gyEyCYCHSiayJa/EKg9vC0NvhW1fQUWRx8JTSjVvmvRbon5TKEv5FZsliXkrso+UdzwLMJD9o6ciU0o1c5r0W6LR9xFyyT8Y1S2WD37KocZtT06WkArigF3LTry9UspnadJvwa5ISSCvuJLvMvdZBYHhENcHspZ6NjClVLOlSb8FG9OzDa2D/a2J0w/pkAbZGVBT7bnAlFLNlib9FizQz8kVgxJYuCaXrfkHrcLEoeAqhbw1ng1OKdUsadJv4W4f3ZkgPwePfWJPrtIhzXrVdn2l1HFo0m/hYsICuXVkZxatyyNj535onQCtErRdXyl1XJr0vcAvRyQTGx7I/1u4EWMMJA6xrvSN8XRoSqlmRpO+FwgJ8OOusV1J33mAz9bnWU08JbuhqNYNXle55wJUSjUbmvS9xJTURDrFhvLoJxtxxQ+xCrOWgasC5t4A/+oOpfs8G6RSyuM06XsJP6eD+8f3ZFt+Ka9uDQX/UNj8Cbw2EdZ/YA3NsO59T4eplPIwTfpe5NwebRjVPZYnF2+nqt0gWPMO5GTApJegTW9YPdfTISqlPKzeSV9EnCLyk4gssN8ni8gyEckUkTkiEmCXB9rvM+31SfX9bvVzIsIDF/eiorqG/1WlQEg0XPc+9LkC+k2G7OWwf7unw1RKeVBDXOn/FthQ6/0/gCeMMV2AA8A0u3wacMAuf8KupxpYp9gwbjo7mbt3DGblVemQdLa1os8k63XNO54LTinlcfVK+iKSAFwEvGi/F+Bc4NBM3bOBifbyBPs99voxdn3VwH59bldiw4N4cP563IcGY4tIhI5nW0082pVTKZ9V3yv9J4E/Am77fTRQaIw5NPBLNhBvL8cDWQD2+iK7/s+IyC0iki4i6fn5+fUMzzeFBfrxp/E9WJVdxFs/7jqyot9kKNgCu3+y3rvdcGCnZ4JUSnnEGSd9EbkY2GuMyWjAeDDGzDTGpBpjUmNjYxvyo33KxAHxDOsUzT8+3kh+SaVV2GsCOAOsJp7t38DMkfBUP8hd5dlglVJNpj5X+sOBS0VkB/A2VrPOU0CEiPjZdRKAHHs5B0gEsNe3Bgrq8f3qBESEv1/WhwqXm/9baN9yCY6ErufB8pkw+xIos//5t3/juUCVUk3qjJO+MeY+Y0yCMSYJuApYbIyZCnwJ2HcNuQH40F6eb7/HXr/YGG1cbkydY8P41chOvP9TDj8cGnN/6K0Q1hbGPgS/XgGRybBLx+lRylc0Rj/9e4F7RCQTq81+ll0+C4i2y+8BpjfCd6uj3D66Cx2jQ/jzB2uprK6B5HPgnnVw9t3gHwQdhllJX8+/SvmEBkn6xpivjDEX28vbjDFDjDFdjDGTjTGVdnmF/b6LvX5bQ3y3OrEgfyd/m9CHbftKeem7HcdW6DAUyvZBwdYmj00p1fT0iVwfMLJbLON6xfGfxVvYU1Tx85WJ9vj7OhSzUj5Bk76PeODiXlS7zZGbuofEdLNu8O5a4pnAlFJNSpO+j0iMCuFXIzszf9Vulm2r1WnK4bCmWNSZtpTyCZr0fchtIzsTHxHMg/PX4apxH1nRIc16aEuHXlbK62nS9yHBAU4euKQXG/eU8O/PNh9ZcbhdX6/2lfJ2mvR9zPm923L1kESe+2or32y2h7loP9B6Ulfb9ZXyepr0fdADF/eme1w498xdyd7iCqu/fvuB2q6vlA/QpO+DggOcPHPNQA5WVnPXnJXUuI11M3f3TzqXrlJeTpO+j+oaF87fJvThh60FPLZoo/VkrtsFz4+Ad38JS56F6ipPh6mUamB+J6+ivNWVqYmszi7kv19vo2ebnkwcfb81veLOJdZInNUVMOIeT4eplGpAeqXv4x68pDdpnaL44/ub+Cn5ZrhmjjU2T8fh8NPrOiaPUl5Gk76P83c6eHZqCnGtArnltQx2F9pt+gOvhf1bdQROpbyMJn1FVGgAL14/mIqqGq6btYz9pVXWhCsBYdbVvlLKa2jSVwB0bxvOizekkn2gnF+8vJyDJhD6XA7r3ofKEk+Hp5RqIJr01WFDO0XzzDWDWLu7mFtfS6eq31RwlVqJXynlFTTpq58Z1yuOx67ox/eZBfz6Gycmprs28SjlRbTLpjrGFSkJlFS4eOij9czvcC4Tsp6Drx4Fdw24ymDQ9RDb3dNhKqXOgCZ9dVw3Dk+mtKqGhxcVcUFIMIFf/T9ArJUFW+Gatz0an1LqzGjzjqrT7aM6M2nkIAaUzeA/Q7+CB/ZbD2ttWQSFWZ4OTyl1BjTpqzqJCPde0J2LU7rwr6938+HqXEi50XpgK+MVT4enlDoDmvTVCYkIf7+sD0OSovjDvNWsLGkF3c6HFa/q2DxKtUCa9NVJBfo5ee7aQcS1CuTmV9Mp6HktlO6FjQs8HZpS6jRp0lenJDoskFk3WE/tXvl5CDWtEiH9JU+HpZQ6TZr01SnrFhfOKzcNZk+Ji1kVo2HHt5C1HIpyoHAX1FR7OkSl1EmccdIXkUQR+VJE1ovIOhH5rV0eJSKficgW+zXSLhcReVpEMkVktYgMaqidUE0npWMUs28awqsVI6jCD2aNgyd6wZN94fnhkLfO0yEqpU6gPlf61cDvjDG9gDTgDhHpBUwHvjDGdAW+sN8DXAh0tf9uAZ6rx3crD0pNiuKJm8Zyi/s+ng29A9f4J+DCx6BsP7xwLix/QYdkVqqZOuOkb4zJNcassJdLgA1APDABmG1Xmw1MtJcnAK8ay1IgQkTanXHkyqMGJ0Ux9arreKxgOH/amYIZcgvc9gMkjYCFv4eFf/B0iEqp42iQNn0RSQIGAsuAOGNMrr1qDxBnL8cDtZ/oybbLVAs1rlccvzm3C+9kZPP6sl0QFgvXzIXBN8OPL0LuKk+HqJQ6Sr2TvoiEAe8CdxljimuvM8YY4LR+54vILSKSLiLp+fn59Q1PNbK7xnZjdPdY/jp/Hek79oPDAWP+AsGR8OlftJlHqWamXklfRPyxEv4bxpj37OK8Q8029uteuzwHSKy1eYJd9jPGmJnGmFRjTGpsbGx9wlNNwOEQnrxqIAmRwdz2xgryiisgqDWMvBe2fw2Zn3s6RKVULfXpvSPALGCDMebftVbNB26wl28APqxVfr3diycNKKrVDKRasNbB/vz3ulRKK6u57fUMqqrdkHoTRHWCzx6wRudUSnHFz8AAABYmSURBVDUL9bnSHw5cB5wrIivtv/HAo8A4EdkCjLXfAywEtgGZwAvA7fX4btXMdG8bzmOT+rFiVyF//Wgd+AXAmAdh73odj1+pZuSMh1Y2xnzH4bF2jzHmOPUNcMeZfp9q/i7u1541OUX89+tttGsdxLThFxOcOBQ+uQ9aJ0CXY/6zUEo1MX0iVzWoP57fg7E943j8080M+8diZsQ+iCsiCd6cAmvf9XR4Svk8TfqqQTkdwgvXp/DOr4YxrFM0/1pSyMi9v6cgsj/MmwbpL3s6RKV8miZ91eBEhMFJUTx3bQpf/G4UcXFxnJVzJ5vCh2A+/iMU7/Z0iEr5LE36qlElx4Qy99Zh3DSqJ9P2XUNNTQ0VX/375BueSEURvPML2JfZMEEq5UM06atG5+90cO8FPXj4hvF84B6BrJhNcX72kQqr34G3p576pCzr58O692DBXfrwl1KnSZO+ajKje7Qh4ZI/42dcLH75AQ5WVsP2b+GDX1kTsqx7/9Q+aMNHIE5raGe9OazUadGkr5pU2uDB5HW8hHGlC3jk+dm451wLUZ2tv2XPnfzKvaIYtn0JQ26BdgPg0z9DZUnTBK+UF9Ckr5pc+0v+QohU8bf9f6C4ooY1o2bCsNth90/WpCwnsuVTqKmC3hPhon9BSS58/Y9j67nd1q+Awqxj1ynlwzTpq6YX2w3pczlOp5M/B93HZW/u5vXys6wxe5Y+e+JtN8yHsDhIGAIJqTDoelj6nJXgDw33UJwLr02EeTfB5w82/v4crboKfnhGf4GoZumMn8hVql4mPItjzAM8EhRPxdxV/HnhdromX8KQDW8hhVkQkXjsNq5y2PIZ9L/aGs0TYMxDsHOJleAjHoI+kyDjFaiugLi+sOVzqHGB07/p9i3zc/j0fqgshtF/arrvVeoU6JW+8gz/IIhMonWwPzOvS+HqIR24Z/tgjDGY5S8cf5uti8FVBj0vOVIWGg13LIMrX4NWCfDdv6F1PNzytZVwK4tgx3dNs0+HZC2zXpfPhKrSpv1upU5Cr/SVxzkcwv9d1oeH/Z18vDyVMUtfILDGhXQcBh3SIKyNVXHDRxAUAUlnH/UBTuh1qfVXvBtCY60r+9YJ4BcMmz6GzqObboeylkNINJQVwIpXIe22pvtupU5Cr/RVsyAi/OXinuxJ+QMrXElUL38R5l4Hj3eF/46EL/8PNi2E7uNP3FTTqv2R9QEhVrLftLB+/fkP7ISVb1kPhZ1MjQt2r4B+U6DjcKttv8Z18u2y06Fkz5nHqNQp0qSvmg0R4aYJ41iU+gK9yl/kw9TZMOYB8AuCb/5pJd3eE0/+QbV1vxCKsmDPmjMLKm8dvDjWepbgXz3gwztg98q66+9Zbd1PSBwCw++C4mxYM+/E37F3A7x0Pnwy/cxiPFOFu+Dzh2BG2on3SXkVTfqqWRERHrikN2N6J/Db7/xZ0PpqmLYI/rAVblwIXc87vQ/sdgEgVhPP6cr6EV4eDw4/mPI69J0Ma9+HF86F7Iw6trG7nCYMga7joE1v+P5Jqwvp8bjdsOBucFdbN6mrK08/ztNVtt96Avqp/vD9U1CQCXXdR1FeR5O+anacDuHJqwYwOCmSu+es5J+LNlLqbAVJw0HqmsKhDmFtrKvuTf87ve22fQWvToCQKLjpE+vm8aVPw91rrS6j8+88/rARWcugdaJ1M1kEzr4L8jdaTxwfz0+vwa4l0GsiVB20nlBubAv/AJsXwdn3wF1roP8UWP+B3nT2EZr0VbMU5O/kxesHM75vO2Z8uZVRj3/F3B+zqHCdwdSL3S+E3FVQZE/JfHAvFGy1Xl3lx7b3b1gAb0yGyCT4xScQ2fHIupAouPgJa0awb/917HdlLbdOMof0vhxie1jTRh59FX8w3yrvOBwuex78Q0/t5JS7ypqfYEYaLP671Tx0qjZ8BGvnwcg/WhPYt06A/tdYJ5yNp3liVC2SmGY8YFVqaqpJT0/3dBjKw1bsOsDfPlrPyqxCgv2djOgaw9hecfRPiCA5JpQAv5Ncu+RvhhmDIT4FSvOttuzaojrB4Jth4FSrGeiD2yF+EFwz10ryx/PuL2HdB3Dr1xDX2yoryoYnesOFj8HQW4/UzfwCXr8cxv7VuvIH60Tz3s3WZ9z2PcR2hznXWjd0715/5DmEzx+CXUut9bE9rOX1H1i9mOL6wK4fwLghppvVq6nDWdZJas8a64ZyeSGc9WurF1TZfpgxFMLj4OYvj9zwdrvh6f4Q3QWus8c/Ks61mrHCYq0TV5/LIaLDKR+zZscYmPcLcFXAlbPBL9DTETUqEckwxqQed50mfdUSuN2G77fu49N1eXy+IY/cogoA/BxCckwoiVEhtG0dRLtWQfRs14pBHSOJCg2wNjYGXr7Q6oWTONhqbw+NsZ6YrSiyhnbIWmZdabtKIfkcuOotCAyrO6DSfTBjCER0hGmfWgl07bvWQ2K3fAXtB/68/ptTYMf38JsVEBIDn9xr9eMfOR1G32fVWfmWdcP45sXWCSprOcwaZ41LVL4fyg9YMQ67A86603qCuSTPOglsXmTVr6r1FHBwlNWdtTTfemitugI2f2LF17bvz+Nb/Ah8+zjcvQ7C28HrV8DOHyCuF+TY9y8G/9I6oTmcp3fwjLFOTKezXVUpBIQe+zk7vrNOyEevO5kNC2DOVGu59+VwxawjJ1YvpElfeRVjDJvzDrJxTzGb9pSwOe8guwvL2VNcwf7SI+3syTGh9GgbTqfYUJJjwvB3CsUV1ZRUuAgN8KNzbBidYkNp2yoIx56V1s1MERj/L+vhsZNZ+5519Tjoerjkaav3zYpXYXoWOI96BGZfJjybZt0MdlfDmrkw7E4Y9/CR5FO2H/7ZBc6+G0bfbyX84hy4M91KcqX5Vk+moFbHj6emGvLWWtvE9bGuzF1l8N2T8MPTVtKvfZKprWAr/GeQ9WskMAz+9zsY/zgMuRn2b7eGulj+X+vexuUvntq/D1hNWu/+0johTZp17DMWx7P0OWsgvStfhR4XHSk/dFKMT4Wp79T9K+xorgrrBO0fbP37L37Y+rc//5FT2/5MuGus+zgdz7YeIKwt83OI6X78p84biCZ95TPKqqpZk13Eil2F/LTrAJl7D7JrfxnV7rr/O3cItA72JzIkgPAgPwL8HPg7HTgdQnWNocZt8HMK8RHBJEaFEB8RTHRYAFGhAXRc9W9a//gUFefcT8CWhTgCw+DGOm7aLrofljxjLY95wLqRevSN6Zcvsq7qz77bav6Z+DwMuLr+/zCFu6zeQQOvA7+A49eZdZ7VrFO2DzoMg2vf/Xl8S5+3fqEkjYArXoTwtif+TleF9azFlk8hvD0czIOxD1nNTXXdkD/0a8nhb53cbltiNUcV58KzQ62b6Ad2HGmKOlkMYN17+eJvcN0H0GkUfHyvdQJLu8O6iR3X98RX/WX7rZPmju+g56Uw6DoIjqy7fkkevPdL2P6NdVN/yuvQfoB14/+TeyH9Jevp8WmfWjf8G4EmfeXTXDVusvaX4TbQKtiP8EB/iitcbM0/yLb8UvKKKzhQVsWBMhelldVUVbupqnZT7Tb4OwU/h4PK6hqyD5Szt+ToLpWGJ/1nMNH5A24j/NdM5JWgawkL9KOqxk15VQ3lVTUE+TuJC6zkkarH+D7oHL4IuRCnCDXG4Kpx46o2uI3h8soPua1yFkXSigMB7ZjdaxbicFJQWsm+g5W4agytg/1pHexPsL8Tg8FtrGausEA/woL8rHIDbmN9pqvGUF1jMBirTqAfwQFOSiqqKSp3UVzholWQP0MLPiR17d+o8m/NgrPnkWeiCfJ3EBHiT0RIAA4RorZ+SO/l9+Iw1VQFRHKwVWeqAiPB7cYYNxX+EeSF9SI3uCup258n4cAyMvo+SF6H8aSs/AttcxZxMKo3YgwB5XmAoajL5RT1vYGA0lziF1zLwZj+bB54P4M+n8LBdmex+6LZtP3fjYTnfs/iUe/TuiqPlCV3UB0cQ2lcKoFF2wgoyaY4cTR5wx7AERJBdY2h3FVDTWEOgxecR0n7s9l70UsAVFRW0f6re4jZ9gEAVQER5MWNIKvT1RTHDMTfz0lYoB8RlbtpkzmX1qtnIa4yXFHdCdi/EbdfEMVdJlKYOIYDbYZQ6QzH6RCc1BC5ZwmJX9+Dw1VCedrdBK16FUdZAQdGPETIpvcIyl1Oca+phG35EHd4e1zXL8QZFo0xbshahsnOoOZAFqY4m5rQdrS+/MxmmdOkr1QDqXDVkFtkNSPtL62isKwKV1UFo5ffQrvCFczp9i8yAgZzsLKaQD8nIQFOgvydVLhqOFhZTWllNa4aKxnXuA1OhxDgdODnFJwOIdq1m4d3XAvAXSGP8nlpJ4wxxIQHEh0agJ/DQVG5i6JyFxXVNThEcAhUuw0HK6pP+IumLgFOB1U1blpRypyAh3my+goWuQfXWb+n7OQsxzo6Sw5dHTmEU45BMAhtpYAoOQhAjRH+6LqVd93n2FsabnQuYoLzBwpMOHtNBK2llPMcGThxU4UfWaYNk6oepIgwbnR+wkP+r/JZTQrjnBk87JrKrBqruWeAZPJMwNM4cLPd3Y4DhHOBYzl7iWC662bWu5M4y7GOqX6fM0AyGVf1T3aZuJ/tRxsOcJZjHSOcaxjnyKCVlLHe3ZEMd1dr/xy5uI2w0D2Up6ovZ4tJoKfs5Hrnp1zq/IFQqaTaONhsEgmnjHZSgJ+42eKO53bXb9liEoimiBkBT5Pm2EC5CeAPrltZ4B5GmmM9s/0fZZ1JYl7NSK5zfkpPhzUMeJkJJNdEsS2kL+Omv3PaxxM06SvV+MoPwKo5MHha/Uf0fOkCiEyGy547rc2MMVRWW78uHCKIAxwi+DkEf6cDAUqrqimpqKasqoZWQX60CvYnyN9JeVUN+w5WUlBaRbC/k4gQf8KD/KhwuSm0fwUBh09QDpGfnbgO/QU4hNCKXEL2rYZW7Shrk0K5y/q1U1XtprLaeq1xG2qM9QtEDu6h/dY5RBT8xOYhj+CITCTQz0mly0X3z24kOu97imIGsuOSdwkLCaSq2s3BymoOVlRjMAgCAmH7VtFz6b2ElWw9/G9SHdCK7AH3sL3TVA5WViMCwf5Ogv2dBPo7CHA6CfBz4FdTRuim94hYO5uAom0UxqWR1+ZssmJGUBqaeLhX76H99He7iClaTezeHwjfvwZXYBRloe05GNKBXW3P46AJpMJVg4gQQDXdst6hIHYIJa27IQhVNW5isz5l5Krf48DNvtBurI6fQk7bc3GGRBMa5Eeb8CCGdY4+zpE+OU36SrUkh/6fPN0H0bxRcS588Vc45w8Q3fnk9V0VVnu9cUPySGjX//R7G7ndTdezZ8d31hPfiUMb9Hg3q6QvIhcATwFO4EVjzKN11dWkr5RSp+9ESb9JO6qKiBOYAVwI9AKuFpFeTRmDUkr5sqZ+OmEIkGmM2WaMqQLeBiY0cQxKKeWzmjrpxwO1Z6rOtssOE5FbRCRdRNLz8/ObNDillPJ2ze45ZGPMTGNMqjEmNTY21tPhKKWUV2nqpJ8D1H72OMEuU0op1QSaOun/CHQVkWQRCQCuAuY3cQxKKeWzmnRidGNMtYjcCSzC6rL5kjFmXVPGoJRSvqxJkz6AMWYhsLCpv1cppVQzfyJXRPKBnfX4iBhgXwOF01L44j6Db+63L+4z+OZ+n+4+dzTGHLcnTLNO+vUlIul1PZXmrXxxn8E399sX9xl8c78bcp+bXZdNpZRSjUeTvlJK+RBvT/ozPR2AB/jiPoNv7rcv7jP45n432D57dZu+Ukqpn/P2K32llFK1aNJXSikf4pVJX0QuEJFNIpIpItM9HU9jEZFEEflSRNaLyDoR+a1dHiUin4nIFvs10tOxNjQRcYrITyKywH6fLCLL7GM+xx7mw6uISISIzBORjSKyQUSGefuxFpG77f+214rIWyIS5I3HWkReEpG9IrK2Vtlxj61Ynrb3f7WIDDqd7/K6pO9jE7VUA78zxvQC0oA77H2dDnxhjOkKfGG/9za/BTbUev8P4AljTBfgADDNI1E1rqeAT4wxPYD+WPvvtcdaROKB3wCpxpg+WEO3XIV3HutXgAuOKqvr2F4IdLX/bgFOazJlr0v6+NBELcaYXGPMCnu5BCsJxGPt72y72mxgomcibBwikgBcBLxovxfgXGCeXcUb97k1cA4wC8AYU2WMKcTLjzXWUDHBIuIHhAC5eOGxNsZ8A+w/qriuYzsBeNVYlgIRItLuVL/LG5P+SSdq8UYikgQMBJYBccaYXHvVHiDOQ2E1lieBPwJu+300UGiMqbbfe+MxTwbygZftZq0XRSQULz7Wxpgc4HFgF1ayLwIy8P5jfUhdx7ZeOc4bk77PEZEw4F3gLmNMce11xuqT6zX9ckXkYmCvMSbD07E0MT9gEPCcMWYgUMpRTTleeKwjsa5qk4H2QCjHNoH4hIY8tt6Y9H1qohYR8cdK+G8YY96zi/MO/dyzX/d6Kr5GMBy4VER2YDXdnYvV1h1hNwGAdx7zbCDbGLPMfj8P6yTgzcd6LLDdGJNvjHEB72Edf28/1ofUdWzrleO8Men7zEQtdlv2LGCDMebftVbNB26wl28APmzq2BqLMeY+Y0yCMSYJ69guNsZMBb4EJtnVvGqfAYwxe4AsEeluF40B1uPFxxqrWSdNRELs/9YP7bNXH+ta6jq284Hr7V48aUBRrWagkzPGeN0fMB7YDGwF7vd0PI24n2dj/eRbDay0/8ZjtXF/AWwBPgeiPB1rI+3/KGCBvdwJWA5kAu8AgZ6OrxH2dwCQbh/vD4BIbz/WwF+BjcBa4DUg0BuPNfAW1n0LF9avuml1HVtAsHoobgXWYPVuOuXv0mEYlFLKh3hj845SSqk6aNJXSikfoklfKaV8iCZ9pZTyIZr0lVLKh2jSV0opH6JJXykPEJEdIhLj6TiU79Gkr5RSPkSTvvIZIpJkTz7ygj0xx6ciElxH3c4i8omIZIjItyLSwy5/RUSeF5F0EdlsDwCHPbnHyyKyxh4Fc7Rd7hSRx+1JQFaLyK9rfc2vRWSFvU2PRv8HUApN+sr3dAVmGGN6A4XAFXXUmwn82hiTAvweeLbWuiSseRsuAp4XkSDgDqzBEPsCVwOz7fJb7PoDjDH9gDdqfc4+Y8wgrEkwft8wu6fUifmdvIpSXmW7MWalvZyBlZB/xh6q+izgHWucL8Aa8+WQucYYN7BFRLYBPbDGQfoPgDFmo4jsBLphjRT5vLHHfzfG1J4o49CoqBnA5fXfNaVOTpO+8jWVtZZrgOM17ziwJuoYUMdnHD1g1ZkOYHUolhr0/0XVRLR5R6mjGGsimu0iMhkOT0Tdv1aVySLiEJHOWCM+bgK+Baba9bsBHezyz4BbD43/LiJRTbcnSh1Lk75SxzcVmCYiq4B1/Hye5V1YQ/t+DPzKGFOB1ebvEJE1wBzgRmNMJdY8vruA1fZnXdOE+6DUMXRoZaVOg4i8gjWG/7yT1VWqOdIrfaWU8iF6pa98mojMwJp3tbanjDEveyIepRqbJn2llPIh2ryjlFI+RJO+Ukr5EE36SinlQzTpK6WUD/n/RAciAEyXY7IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smVPMOa-gODS",
        "outputId": "7a5de962-9366-4c9b-8061-e0aee6f4eb13"
      },
      "source": [
        "net = FC_Net()\n",
        "test_set = FC_Net_Dataset(split=2)\n",
        "test_loss = test(net, loss_fn, test_set, batch_size, lr, epoch=argmin_loss, name='fc_net')\n",
        "print(\"Test LOSS: \\t%.4f\" % (test_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LOSS: \t28.3152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3YDAynvd0B0"
      },
      "source": [
        "# R_Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUblweVfd1Z_"
      },
      "source": [
        "class R_Net_Dataset(Dataset):\n",
        "    def __init__(self, split, eval_len=1, window_size=5, csv_dir='dataset/train.csv'):\n",
        "        \"\"\"\n",
        "        Keyword arguments:\n",
        "        split -- an integer either 0, 1, or 2 which indicates train, validation, or test respectively\n",
        "        eval_len -- an integer indicating the number of future timestamp to be predicted\n",
        "        \"\"\"\n",
        "        super(R_Net_Dataset, self).__init__()\n",
        "        df = pd.read_csv(csv_dir)\n",
        "        df['datetime']=pd.to_datetime(df['datetime'])\n",
        "        df['week_day']=df['datetime'].dt.dayofweek\n",
        "        # df['date']=df['datetime'].dt.day\n",
        "        # df['month']=df['datetime'].dt.month\n",
        "        df['hour']=df['datetime'].dt.hour\n",
        "        df = df.drop(columns=\"datetime\")\n",
        "        data = np.split(df, [int(.7*len(df)), int(.85*len(df))])\n",
        "        self.data = np.array(data[split])\n",
        "        self.eval_len = eval_len\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        min_start = self.window_size+1\n",
        "        max_start = len(self.data)-1 - self.eval_len\n",
        "        idx = np.random.randint(min_start, max_start)\n",
        "        prev_nat_demand = np.reshape(self.data[idx-1 - self.window_size: idx-1, 0], (-1,1))\n",
        "        curr_feat = np.concatenate((prev_nat_demand, self.data[idx - self.window_size: idx, 1:]), axis=1)\n",
        "        curr_nat_demand = np.reshape(self.data[idx, 0], -1)\n",
        "        return curr_feat, curr_nat_demand\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZiZr_Ska9Q"
      },
      "source": [
        "class R_Net(nn.Module):\n",
        "    def __init__(self, input_size=18, hidden_size=32, dropout=0, num_layers=1):\n",
        "        super(R_Net, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.bn1 = nn.BatchNorm1d(32, affine=True)\n",
        "        self.fc3 = nn.Linear(32, 8)\n",
        "        self.bn2 = nn.BatchNorm1d(8, affine=True)\n",
        "        self.fc4 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x.double())\n",
        "        x = self.fc1(x[:,-1])\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLWCQtowQqKo",
        "outputId": "8d864d16-0242-43cf-e66f-53190f76a7e7"
      },
      "source": [
        "train_set = R_Net_Dataset(split=0)\n",
        "val_set = R_Net_Dataset(split=1)\n",
        "\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "r_net = R_Net();\n",
        "r_net.double()\n",
        "loss_fn = nn.L1Loss()\n",
        "batch_size, n_epoch, lr = 32, 200, 5e-3\n",
        "train_size, val_size = 365, 365\n",
        "argmin_loss = train(r_net, train_set, val_set, loss_fn, batch_size, lr, n_epoch, train_size, name='r_net')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP \t5] \t\tTrain LOSS: \t748.1106 \t\tVal LOSS: \t793.2274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb1pdxmYnuWc"
      },
      "source": [
        "net = R_Net()\n",
        "test_set = R_Net_Dataset(split=2)\n",
        "test_loss = test(net, loss_fn, test_set, batch_size, lr, epoch=argmin_loss, name='r_net')\n",
        "print(\"Test LOSS: \\t%.4f\" % (test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AprDSL4TlZJa"
      },
      "source": [
        "# MB_Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnOarW-lm0C4",
        "outputId": "582e92e8-fe73-47b9-c141-aec2390839cd"
      },
      "source": [
        "    def __getitem__(self, idx):\n",
        "        min_start = self.window_size+1\n",
        "        max_start = len(self.data)-1 - self.eval_len\n",
        "        idx = np.random.randint(min_start, max_start)\n",
        "        prev_nat_demand = np.reshape(self.data[idx-1 - self.window_size: idx-1, 0], (-1,1))\n",
        "        curr_feat = np.concatenate((prev_nat_demand, self.data[idx - self.window_size: idx, 1:]), axis=1)\n",
        "        curr_nat_demand = np.reshape(self.data[idx, 0], -1)\n",
        "        return curr_feat, curr_nat_demand\n",
        "\n",
        "class MB_Net_Dataset(Dataset):\n",
        "    def __init__(self, split, eval_len=1, mb_len=5, window_size=5, csv_dir='dataset/train.csv'):\n",
        "        \"\"\"\n",
        "        Keyword arguments:\n",
        "        split -- an integer either 0, 1, or 2 which indicates train, validation, or test respectively\n",
        "        eval_len -- an integer indicating the number of future timestamp to be predicted\n",
        "        \"\"\"\n",
        "        super(MB_Net_Dataset, self).__init__()\n",
        "        df = pd.read_csv(csv_dir)\n",
        "        df['datetime']=pd.to_datetime(df['datetime'])\n",
        "        df['week_day']=df['datetime'].dt.dayofweek\n",
        "        # df['date']=df['datetime'].dt.day\n",
        "        # df['month']=df['datetime'].dt.month\n",
        "        df['hour']=df['datetime'].dt.hour\n",
        "        df = df.drop(columns=\"datetime\")\n",
        "        data = np.split(df, [int(.7*len(df)), int(.85*len(df))])\n",
        "        self.data = np.array(data[split])\n",
        "        self.eval_len = eval_len\n",
        "        self.window_size = window_size\n",
        "        self.mb_len = mb_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        min_start = 1 + self.window_size + self.mb_len\n",
        "        max_start = len(self.data)-1 - self.eval_len\n",
        "        idx = np.random.randint(min_start, max_start)\n",
        "        prev_nat_demand = np.reshape(self.data[idx-1 - self.window_size - self.mb_len: idx-1, 0], (-1,1))\n",
        "        curr_feat = np.concatenate((prev_nat_demand, self.data[idx - self.window_size - self.mb_len: idx, 1:]), axis=1)\n",
        "        curr_nat_demand = np.reshape(self.data[idx, 0], -1)\n",
        "        return torch.tensor(curr_feat, dtype=torch.float64), torch.tensor(curr_nat_demand, dtype=torch.float64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "a = MB_Net_Dataset(split=0)\n",
        "for i, (x,y) in enumerate(DataLoader(a, batch_size=1)):\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 25, 18])\n",
            "torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Nb6mEcnL4j"
      },
      "source": [
        "class MB_Net(nn.Module):\n",
        "    def __init__(self, input_size=18, hidden_size=32, dropout=0, num_layers=1):\n",
        "        super(R_Net, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc1 = nn.Linear(hidden_size, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x.double())\n",
        "        x = self.fc1(x[:,-1])\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}